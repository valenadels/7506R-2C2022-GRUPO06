{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta segunda parte del trabajo se pide analizar si es posble agrupar los datos en función de algún criterio. Usaremos el algoritmo de K-Means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (70158904.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [17]\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster im# rt KMeans\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Otras librerías\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.cluster im# rt KMeans\n",
    "from pyclustertend import hopkins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este tipo de problemas se trata de agrupar los datos. Agruparlos de tal\n",
    "forma que queden definidos N conjuntos distinguibles, aunque no\n",
    "necesariamente se sepa qué signifiquen esos conjuntos.\n",
    "El agrupamiento siempre será por características similares.\n",
    "En esta ocasión se nos pide analizar si es posible agrupar los datos en función de algún criterio utilizando el algoritmo K-Means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritmo de K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PASO 1: Elegir la cantidad de clusters $k$\n",
    "- PASO 2: Elige al azar un centroide para cada clúster (no necesariamente un punto del data set)\n",
    "- PASO 3: El algoritmo asigna cada punto al centroide más cercano para obtener clústeres iniciales\n",
    "- PASO 4: Para cada clúster, el algoritmo recalcula el centroide mediante el promedio de todos los puntos del clúster\n",
    "- PASO 5: K-Means vuelve a reasignar los puntos usando los nuevos centroides. Calcula nuevos\n",
    "grupos\n",
    "- PASO 6: El algoritmo repite el cálculo de los centroides y la asignación de puntos hasta que estos dejen de cambiar de clúster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos de vuelta la database despues del preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_properati = pd.read_csv('nueva_database_properati.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cómo determinar la tendencia al agrupamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estadística de Hopkins (Lawson y Jurs 1990) se utiliza para evaluar la tendencia de agrupación de un\n",
    "conjunto de datos midiendo la probabilidad de que un conjunto de datos dado sea generado por una\n",
    "distribución de datos uniforme.\n",
    "En otras palabras, prueba la aleatoriedad espacial de los datos.\n",
    "La idea es comparar una muestra cualquiera con una muestra uniforme (creada de forma aleatoria) y ver\n",
    "cómo se distribuyen los ejemplos (los puntos) en dicho espacio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcionamiento: Sea D un conjunto de datos reales:\n",
    "- PASO 1: Tomar una muestra uniformemente de n puntos $(p_1,..., p_n)$ de D\n",
    "- PASO 2: Calcular la distancia ($x_i$) de cada punto real a cada vecino más cercano\n",
    "- PASO 3: Generar un conjunto de datos simulados (randomD) extraído de una distribución uniforme aleatoria con n puntos ($q_1,...,q_n$) y la misma variación que el conjunto de datos reales original D\n",
    "- PASO 4: Calcular la distancia ($y_i$) desde cada punto artificial hasta el punto de datos real más cercano\n",
    "- PASO 5: Calcular la estadística de Hopkins (H) como: la distancia media del vecino más cercano en el conjunto de datos\n",
    "aleatorios dividida por la suma de las distancias medias del vecino más cercano en el conjunto de datos real y simulado.\n",
    "\n",
    "$H = \\frac{\\sum_{i=1}^{n} y_i}{\\sum_{i=1}^{n} y_i+\\sum_{i=1}^{n} x_i}$\n",
    "\n",
    "Si D está distribuida de forma uniforme, entonces ∑ xi y ∑ yi serían muy parecidos, entonces H sería aproximadamente 1⁄2 (0.5).\n",
    "\n",
    "Pero si hay clústeres en D, las distancias de los puntos artificiales ∑ yi serían mucho más grandes que las distancias de los puntos reales: ∑ xi y por lo tanto H sería mayor que 0.5.\n",
    "\n",
    "Un valor de H superior a 0,75 indica una tendencia a la agrupación en un nivel de confianza del 90 %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos la tendencia al clustering del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2021-09-09'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tomas/Escritorio/Facultad/Orga_De_Datos/TP1/TP_parte_dos.ipynb Celda 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tomas/Escritorio/Facultad/Orga_De_Datos/TP1/TP_parte_dos.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m hopkins(ds_properati,ds_properati\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyclustertend/hopkins.py:26\u001b[0m, in \u001b[0;36mhopkins\u001b[0;34m(data_frame, sampling_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m     data_frame \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data_frame)\n\u001b[1;32m     24\u001b[0m data_frame_sample \u001b[39m=\u001b[39m sample_observation_from_dataset(data_frame, sampling_size)\n\u001b[0;32m---> 26\u001b[0m sample_distances_to_nearest_neighbours \u001b[39m=\u001b[39m get_distance_sample_to_nearest_neighbours(\n\u001b[1;32m     27\u001b[0m     data_frame, data_frame_sample\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m uniformly_selected_observations_df \u001b[39m=\u001b[39m simulate_df_with_same_variation(\n\u001b[1;32m     31\u001b[0m     data_frame, sampling_size\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m df_distances_to_nearest_neighbours \u001b[39m=\u001b[39m get_nearest_sample(\n\u001b[1;32m     35\u001b[0m     data_frame, uniformly_selected_observations_df\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyclustertend/hopkins.py:80\u001b[0m, in \u001b[0;36mget_distance_sample_to_nearest_neighbours\u001b[0;34m(df, data_frame_sample)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_distance_sample_to_nearest_neighbours\u001b[39m(df: pd\u001b[39m.\u001b[39mDataFrame, data_frame_sample):\n\u001b[0;32m---> 80\u001b[0m     tree \u001b[39m=\u001b[39m BallTree(df, leaf_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     81\u001b[0m     dist, _ \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mquery(data_frame_sample, k\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     82\u001b[0m     data_frame_sample_distances_to_nearest_neighbours \u001b[39m=\u001b[39m dist[:, \u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32msklearn/neighbors/_binary_tree.pxi:833\u001b[0m, in \u001b[0;36msklearn.neighbors._ball_tree.BinaryTree.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:102\u001b[0m, in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m like \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m _asarray_with_like(a, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder, like\u001b[39m=\u001b[39mlike)\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m array(a, dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:2069\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 2069\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:102\u001b[0m, in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m like \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m _asarray_with_like(a, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder, like\u001b[39m=\u001b[39mlike)\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m array(a, dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2021-09-09'"
     ]
    }
   ],
   "source": [
    "hopkins(ds_properati,ds_properati.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cuántos conjuntos elegir?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas mas extendidas en clustering son el método de Elbow y el Índice de Silueta.\n",
    "\n",
    "El método de Elbow consiste básicamente en verificar la evolución de la suma de los cuadrados del error para varias cantidades de clusters y verificar cual es el que brinda un mejor agrupamiento. En donde el gráfico presenta un \"codo\" (se quiebra la pendiente) es la cantidad de clusters adecuada.\n",
    "\n",
    "Coeficiente de Silhouette: Cada punto en el conjunto de datos tiene un coeficiente de Silhouette.\n",
    "Para calcular este coeficiente necesitamos calcular a(i) y b(i):\n",
    "\n",
    "a(i) es la distancia promedio del punto i a cada uno de los puntos de su cluster.\n",
    "\n",
    "b(i) es la distancia promedio del punto i a cada uno de los puntos del cluster más cercano a su propio cluster.\n",
    "\n",
    "Si a(i) > b(i), i está posiblemente mal clasificado.\n",
    "\n",
    "s(i) = b(i) - a(i) / El mayor de (b(i) o a(i))\n",
    "\n",
    "En el peor de los casos s(i) es -1.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14611386fa2cd4265c4f0b62a048cd6d8d2bc09cf37ba48879354d3817581274"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
